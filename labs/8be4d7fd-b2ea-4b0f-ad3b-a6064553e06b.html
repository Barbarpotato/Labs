<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Build Kafka Python Client</title><meta name="description" content="In this lab we will bring back the apache kafka to work with the application environment. In this case we are going to use the apache kafka to a simple python application."/><meta property="og:title" content="Build Kafka Python Client"/><meta property="og:description" content="In this lab we will bring back the apache kafka to work with the application environment. In this case we are going to use the apache kafka to a simple python application."/><meta property="og:type" content="article"/><meta property="og:url" content="https://barbarpotato.github.io/labs/undefined"/><meta name="next-head-count" content="8"/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/Labs/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/Labs/_next/static/chunks/webpack-a39982bd6f80347b.js" defer=""></script><script src="/Labs/_next/static/chunks/framework-ecc4130bc7a58a64.js" defer=""></script><script src="/Labs/_next/static/chunks/main-1e09b50edce1e67f.js" defer=""></script><script src="/Labs/_next/static/chunks/pages/_app-753213cf38d40131.js" defer=""></script><script src="/Labs/_next/static/chunks/pages/labs/%5Bslug%5D-b6b888b0a2f30cff.js" defer=""></script><script src="/Labs/_next/static/A-n-baZxhaPab-FReiSSJ/_buildManifest.js" defer=""></script><script src="/Labs/_next/static/A-n-baZxhaPab-FReiSSJ/_ssgManifest.js" defer=""></script></head><body><div id="__next"><article><h1>Build Kafka Python Client</h1><p>2024-09-20 11:35:05</p><div><div id="content-0"><h1><strong>Introduction</strong></h1><p>Previously we already install the apache kafka using the docker compose, create a simple workflow of how the apache is running. You can visit this site to learn the apache kafka installation and the basic workflow if you are not familir with these topic (<a href="https://barbarpotato.github.io/#/lab/d1c5319b-3019-4576-9368-d3757bf35c6a" target="_blank" style="color: inherit; background-color: transparent;">Introduction to Apache Kafka</a>). To create a Kafka Python client that interacts with your Kafka instance, you can use the&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">confluent-kafka</code>&nbsp;library, which is a high-performance Kafka client built on the librdkafka C library.</p><h3><strong>Install the Kafka Python Client</strong></h3><p>First, you need to install the&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">confluent-kafka</code>&nbsp;library. You can do this using pip. Note: You can create virtual environment of your project folder if you dont want to install this library to your global library package. by using the command: python -m venv &lt;the name of your virtual environment&gt;. then activating the venv using this command: source &lt;your_venv_name&gt;/Scripts/activate.</p></div><div id="content-1"><pre style="background-color: black; color: white; padding:10px; border-radius: 5px;"><code style="color: white;">pip install confluent-kafka</code></pre></div><div id="content-2"><h3><strong>Produce Message</strong></h3><p>Create a Python script to produce messages to the Kafka topic</p></div><div id="content-3"><pre style="background-color: black; color: white; padding:10px; border-radius: 5px;"><code style="color: white;">from confluent_kafka import Producer
import socket

def delivery_report(err, msg):
    if err is not None:
        print(f"Message delivery failed: {err}")
    else:
        print(f"Message delivered to {msg.topic()} [{msg.partition()}]")

p = Producer({'bootstrap.servers': 'localhost:9092', 'client.id': socket.gethostname()})

topic = 'test'

for i in range(10):
    p.produce(topic, key=str(i), value=f"Message {i}", callback=delivery_report)
    p.poll(0)

p.flush()</code></pre></div><div id="content-4"><p></p></div><div id="content-5"><h3><strong>Consume Messages</strong></h3><p>Create another Python script to consume messages from the Kafka topic.</p></div><div id="content-6"><pre style="background-color: black; color: white; padding:10px; border-radius: 5px;"><code style="color: white;">from confluent_kafka import Consumer, KafkaError

c = Consumer({
    'bootstrap.servers': 'localhost:9092',
    'group.id': 'mygroup',
    'auto.offset.reset': 'earliest'
})

c.subscribe(['test'])

while True:
    msg = c.poll(1.0)

    if msg is None:
        continue
    if msg.error():
        if msg.error().code() == KafkaError._PARTITION_EOF:
            print(f'%% {msg.topic()} [{msg.partition()}] reached end at offset {msg.offset()}')
        elif msg.error():
            raise KafkaException(msg.error())
    else:
        print(f'Received message: {msg.value().decode("utf-8")}')

c.close()</code></pre></div><div id="content-7"><p>the consumer script initializes a Kafka consumer using the&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">Consumer</code>&nbsp;class, subscribes to the specified topic(s) with the&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">subscribe</code>&nbsp;method, and retrieves messages from the Kafka topic using the&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">poll</code>&nbsp;method. Finally, the&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">close</code>&nbsp;method closes the consumer and commits the final offsets. This setup allows you to produce and consume messages using your Python Kafka client. Now you can save the file.</p><p><br></p><p>To run the producer and consumer, open two terminal windows or tabs. In the first terminal, run the producer by executing&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">python producer.py</code>, and in the second terminal, run the consumer by executing&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">python consumer.py</code>. The producer script will send 10 messages to the&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">test</code>&nbsp;topic, while the consumer script will receive and print these messages. The producer script initializes a Kafka producer using the&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">Producer</code>&nbsp;class and sends messages to a specified topic with the&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">produce</code>&nbsp;method. A&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">delivery_report</code>&nbsp;callback function confirms message delivery, and the&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">poll</code>&nbsp;method serves delivery reports, which should be called regularly. The&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">flush</code>&nbsp;method waits for all messages in the producer queue to be delivered. On the other hand, the consumer script initializes a Kafka consumer using the&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">Consumer</code>&nbsp;class, subscribes to the specified topic(s) with the&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">subscribe</code>&nbsp;method, and retrieves messages from the Kafka topic using the&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">poll</code>&nbsp;method. Finally, the&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">close</code>&nbsp;method closes the consumer and commits the final offsets. This setup allows you to produce and consume messages using your Python Kafka client.</p><p><br></p><p>Here is the example output about what we are doing:</p></div><div id="content-8"><img style='width:720px;' src='https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2Fkafka_python_client_1.png?alt=media&token=4c079070-9f99-436f-b81c-8b9d0dbada30'/></div><div id="content-9"><img style='width:720px;' src='https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2Fkafka_python_client_2.png?alt=media&token=7a151ac1-e386-4aef-a99a-f2d72fe611fd'/></div><div id="content-10"><h1><strong>Conclusion</strong></h1><p>In conclusion, we successfully set up Apache Kafka using Docker, enabling a reliable environment for message streaming. Following this, we implemented a Kafka Python client using the&nbsp;<code style="color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);">confluent-kafka</code>&nbsp;library, which provides high-performance Kafka producer and consumer capabilities. The producer script was designed to initialize a Kafka producer, send messages to a specified topic, and confirm message delivery through a callback function, while regularly polling for delivery reports and ensuring all messages are delivered with a flush operation. The consumer script was crafted to initialize a Kafka consumer, subscribe to the desired topic(s), retrieve messages, and close the consumer after committing final offsets. By running the producer and consumer scripts in separate terminal windows, you verified the setup by successfully sending and receiving messages. This end-to-end setup demonstrates a functional Kafka environment and a practical Python client for producing and consuming messages, laying a strong foundation for building more complex message-driven applications.</p></div></div></article></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"article":{"blog_id":"8be4d7fd-b2ea-4b0f-ad3b-a6064553e06b","description":"\u003cdiv id=\"content-0\"\u003e\u003ch1\u003e\u003cstrong\u003eIntroduction\u003c/strong\u003e\u003c/h1\u003e\u003cp\u003ePreviously we already install the apache kafka using the docker compose, create a simple workflow of how the apache is running. You can visit this site to learn the apache kafka installation and the basic workflow if you are not familir with these topic (\u003ca href=\"https://barbarpotato.github.io/#/lab/d1c5319b-3019-4576-9368-d3757bf35c6a\" target=\"_blank\" style=\"color: inherit; background-color: transparent;\"\u003eIntroduction to Apache Kafka\u003c/a\u003e). To create a Kafka Python client that interacts with your Kafka instance, you can use the\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003econfluent-kafka\u003c/code\u003e\u0026nbsp;library, which is a high-performance Kafka client built on the librdkafka C library.\u003c/p\u003e\u003ch3\u003e\u003cstrong\u003eInstall the Kafka Python Client\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eFirst, you need to install the\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003econfluent-kafka\u003c/code\u003e\u0026nbsp;library. You can do this using pip. Note: You can create virtual environment of your project folder if you dont want to install this library to your global library package. by using the command: python -m venv \u0026lt;the name of your virtual environment\u0026gt;. then activating the venv using this command: source \u0026lt;your_venv_name\u0026gt;/Scripts/activate.\u003c/p\u003e\u003c/div\u003e\u003cdiv id=\"content-1\"\u003e\u003cpre style=\"background-color: black; color: white; padding:10px; border-radius: 5px;\"\u003e\u003ccode style=\"color: white;\"\u003epip install confluent-kafka\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv id=\"content-2\"\u003e\u003ch3\u003e\u003cstrong\u003eProduce Message\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eCreate a Python script to produce messages to the Kafka topic\u003c/p\u003e\u003c/div\u003e\u003cdiv id=\"content-3\"\u003e\u003cpre style=\"background-color: black; color: white; padding:10px; border-radius: 5px;\"\u003e\u003ccode style=\"color: white;\"\u003efrom confluent_kafka import Producer\nimport socket\n\ndef delivery_report(err, msg):\n    if err is not None:\n        print(f\"Message delivery failed: {err}\")\n    else:\n        print(f\"Message delivered to {msg.topic()} [{msg.partition()}]\")\n\np = Producer({'bootstrap.servers': 'localhost:9092', 'client.id': socket.gethostname()})\n\ntopic = 'test'\n\nfor i in range(10):\n    p.produce(topic, key=str(i), value=f\"Message {i}\", callback=delivery_report)\n    p.poll(0)\n\np.flush()\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv id=\"content-4\"\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv id=\"content-5\"\u003e\u003ch3\u003e\u003cstrong\u003eConsume Messages\u003c/strong\u003e\u003c/h3\u003e\u003cp\u003eCreate another Python script to consume messages from the Kafka topic.\u003c/p\u003e\u003c/div\u003e\u003cdiv id=\"content-6\"\u003e\u003cpre style=\"background-color: black; color: white; padding:10px; border-radius: 5px;\"\u003e\u003ccode style=\"color: white;\"\u003efrom confluent_kafka import Consumer, KafkaError\n\nc = Consumer({\n    'bootstrap.servers': 'localhost:9092',\n    'group.id': 'mygroup',\n    'auto.offset.reset': 'earliest'\n})\n\nc.subscribe(['test'])\n\nwhile True:\n    msg = c.poll(1.0)\n\n    if msg is None:\n        continue\n    if msg.error():\n        if msg.error().code() == KafkaError._PARTITION_EOF:\n            print(f'%% {msg.topic()} [{msg.partition()}] reached end at offset {msg.offset()}')\n        elif msg.error():\n            raise KafkaException(msg.error())\n    else:\n        print(f'Received message: {msg.value().decode(\"utf-8\")}')\n\nc.close()\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv id=\"content-7\"\u003e\u003cp\u003ethe consumer script initializes a Kafka consumer using the\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003eConsumer\u003c/code\u003e\u0026nbsp;class, subscribes to the specified topic(s) with the\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003esubscribe\u003c/code\u003e\u0026nbsp;method, and retrieves messages from the Kafka topic using the\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003epoll\u003c/code\u003e\u0026nbsp;method. Finally, the\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003eclose\u003c/code\u003e\u0026nbsp;method closes the consumer and commits the final offsets. This setup allows you to produce and consume messages using your Python Kafka client. Now you can save the file.\u003c/p\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\u003cp\u003eTo run the producer and consumer, open two terminal windows or tabs. In the first terminal, run the producer by executing\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003epython producer.py\u003c/code\u003e, and in the second terminal, run the consumer by executing\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003epython consumer.py\u003c/code\u003e. The producer script will send 10 messages to the\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003etest\u003c/code\u003e\u0026nbsp;topic, while the consumer script will receive and print these messages. The producer script initializes a Kafka producer using the\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003eProducer\u003c/code\u003e\u0026nbsp;class and sends messages to a specified topic with the\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003eproduce\u003c/code\u003e\u0026nbsp;method. A\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003edelivery_report\u003c/code\u003e\u0026nbsp;callback function confirms message delivery, and the\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003epoll\u003c/code\u003e\u0026nbsp;method serves delivery reports, which should be called regularly. The\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003eflush\u003c/code\u003e\u0026nbsp;method waits for all messages in the producer queue to be delivered. On the other hand, the consumer script initializes a Kafka consumer using the\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003eConsumer\u003c/code\u003e\u0026nbsp;class, subscribes to the specified topic(s) with the\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003esubscribe\u003c/code\u003e\u0026nbsp;method, and retrieves messages from the Kafka topic using the\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003epoll\u003c/code\u003e\u0026nbsp;method. Finally, the\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003eclose\u003c/code\u003e\u0026nbsp;method closes the consumer and commits the final offsets. This setup allows you to produce and consume messages using your Python Kafka client.\u003c/p\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\u003cp\u003eHere is the example output about what we are doing:\u003c/p\u003e\u003c/div\u003e\u003cdiv id=\"content-8\"\u003e\u003cimg style='width:720px;' src='https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2Fkafka_python_client_1.png?alt=media\u0026token=4c079070-9f99-436f-b81c-8b9d0dbada30'/\u003e\u003c/div\u003e\u003cdiv id=\"content-9\"\u003e\u003cimg style='width:720px;' src='https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2Fkafka_python_client_2.png?alt=media\u0026token=7a151ac1-e386-4aef-a99a-f2d72fe611fd'/\u003e\u003c/div\u003e\u003cdiv id=\"content-10\"\u003e\u003ch1\u003e\u003cstrong\u003eConclusion\u003c/strong\u003e\u003c/h1\u003e\u003cp\u003eIn conclusion, we successfully set up Apache Kafka using Docker, enabling a reliable environment for message streaming. Following this, we implemented a Kafka Python client using the\u0026nbsp;\u003ccode style=\"color: rgb(248, 248, 242); background-color: rgb(39, 40, 34);\"\u003econfluent-kafka\u003c/code\u003e\u0026nbsp;library, which provides high-performance Kafka producer and consumer capabilities. The producer script was designed to initialize a Kafka producer, send messages to a specified topic, and confirm message delivery through a callback function, while regularly polling for delivery reports and ensuring all messages are delivered with a flush operation. The consumer script was crafted to initialize a Kafka consumer, subscribe to the desired topic(s), retrieve messages, and close the consumer after committing final offsets. By running the producer and consumer scripts in separate terminal windows, you verified the setup by successfully sending and receiving messages. This end-to-end setup demonstrates a functional Kafka environment and a practical Python client for producing and consuming messages, laying a strong foundation for building more complex message-driven applications.\u003c/p\u003e\u003c/div\u003e","image":"https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2Fkafka_python.png?alt=media\u0026token=10c2db3d-b180-4bad-af2a-90aee92c47e1","image_alt":"Kafka with Pyhton","short_description":"In this lab we will bring back the apache kafka to work with the application environment. In this case we are going to use the apache kafka to a simple python application.","timestamp":"2024-09-20 11:35:05","title":"Build Kafka Python Client"}},"__N_SSG":true},"page":"/labs/[slug]","query":{"slug":"8be4d7fd-b2ea-4b0f-ad3b-a6064553e06b"},"buildId":"A-n-baZxhaPab-FReiSSJ","assetPrefix":"/Labs","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>